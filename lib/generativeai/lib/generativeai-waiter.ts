/**
 * Generative AI Service Management API
 * OCI Generative AI is a fully managed service that provides a set of state-of-the-art, customizable large language models (LLMs) that cover a wide range of use cases for text generation, summarization, and text embeddings. 

Use the Generative AI service management API to create and manage {@link DedicatedAiCluster}, {@link Endpoint}, {@link Model}, and {@link WorkRequest} in the Generative AI service. For example, create a custom model by fine-tuning an out-of-the-box model using your own data, on a fine-tuning dedicated AI cluster. Then, create a hosting dedicated AI cluster with an endpoint to host your custom model. 

To access your custom model endpoints, or to try the out-of-the-box models to generate text, summarize, and create text embeddings see the [Generative AI Inference API](https://docs.oracle.com/iaas/api/#/en/generative-ai-inference/latest/).

To learn more about the service, see the [Generative AI documentation](https://docs.oracle.com/iaas/Content/generative-ai/home.htm).

 * OpenAPI spec version: 20231130
 * 
 *
 * NOTE: This class is auto generated by OracleSDKGenerator.
 * Do not edit the class manually.
 *
 * Copyright (c) 2020, 2025, Oracle and/or its affiliates.  All rights reserved.
 * This software is dual-licensed to you under the Universal Permissive License (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl or Apache License 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose either license.
 */

import * as serviceRequests from "./request";
import * as serviceResponses from "./response";
import * as models from "./model";
import { GenerativeAiClient } from "./client";
import { genericWaiter, genericTerminalConditionWaiter, WaiterConfiguration } from "oci-common";

export class GenerativeAiWaiter {
  public constructor(
    private client: GenerativeAiClient,
    private readonly config?: WaiterConfiguration
  ) {}

  /**
   * Waits forDedicatedAiCluster till it reaches any of the provided states
   *
   * @param request the request to send
   * @param targetStates the desired states to wait for. The waiter will return once the resource reaches any of the provided states
   * @return response returns GetDedicatedAiClusterResponse | null (null in case of 404 response)
   */
  public async forDedicatedAiCluster(
    request: serviceRequests.GetDedicatedAiClusterRequest,
    ...targetStates: models.DedicatedAiCluster.LifecycleState[]
  ): Promise<serviceResponses.GetDedicatedAiClusterResponse | null> {
    return genericTerminalConditionWaiter(
      this.config,
      () => this.client.getDedicatedAiCluster(request),
      response => targetStates.includes(response.dedicatedAiCluster.lifecycleState!),
      targetStates.includes(models.DedicatedAiCluster.LifecycleState.Deleted)
    );
  }

  /**
   * Waits forEndpoint till it reaches any of the provided states
   *
   * @param request the request to send
   * @param targetStates the desired states to wait for. The waiter will return once the resource reaches any of the provided states
   * @return response returns GetEndpointResponse | null (null in case of 404 response)
   */
  public async forEndpoint(
    request: serviceRequests.GetEndpointRequest,
    ...targetStates: models.Endpoint.LifecycleState[]
  ): Promise<serviceResponses.GetEndpointResponse | null> {
    return genericTerminalConditionWaiter(
      this.config,
      () => this.client.getEndpoint(request),
      response => targetStates.includes(response.endpoint.lifecycleState!),
      targetStates.includes(models.Endpoint.LifecycleState.Deleted)
    );
  }

  /**
   * Waits forGenerativeAiPrivateEndpoint till it reaches any of the provided states
   *
   * @param request the request to send
   * @param targetStates the desired states to wait for. The waiter will return once the resource reaches any of the provided states
   * @return response returns GetGenerativeAiPrivateEndpointResponse | null (null in case of 404 response)
   */
  public async forGenerativeAiPrivateEndpoint(
    request: serviceRequests.GetGenerativeAiPrivateEndpointRequest,
    ...targetStates: models.GenerativeAiPrivateEndpoint.LifecycleState[]
  ): Promise<serviceResponses.GetGenerativeAiPrivateEndpointResponse | null> {
    return genericTerminalConditionWaiter(
      this.config,
      () => this.client.getGenerativeAiPrivateEndpoint(request),
      response => targetStates.includes(response.generativeAiPrivateEndpoint.lifecycleState!),
      targetStates.includes(models.GenerativeAiPrivateEndpoint.LifecycleState.Deleted)
    );
  }

  /**
   * Waits forModel till it reaches any of the provided states
   *
   * @param request the request to send
   * @param targetStates the desired states to wait for. The waiter will return once the resource reaches any of the provided states
   * @return response returns GetModelResponse | null (null in case of 404 response)
   */
  public async forModel(
    request: serviceRequests.GetModelRequest,
    ...targetStates: models.Model.LifecycleState[]
  ): Promise<serviceResponses.GetModelResponse | null> {
    return genericTerminalConditionWaiter(
      this.config,
      () => this.client.getModel(request),
      response => targetStates.includes(response.model.lifecycleState!),
      targetStates.includes(models.Model.LifecycleState.Deleted)
    );
  }

  /**
   * Waits forWorkRequest
   *
   * @param request the request to send
   * @return response returns GetWorkRequestResponse
   */
  public async forWorkRequest(
    request: serviceRequests.GetWorkRequestRequest
  ): Promise<serviceResponses.GetWorkRequestResponse> {
    return genericWaiter(
      this.config,
      () => this.client.getWorkRequest(request),
      response => (response.workRequest.timeFinished ? true : false)
    );
  }
}
