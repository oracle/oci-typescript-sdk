/**
 * Model Deployment Data Plane API
 * Model deployments are a managed resource in the OCI Data Science service to use to deploy machine learning models as HTTP endpoints in OCI. Deploying machine learning models as web applications (HTTP API endpoints) serving predictions in real time is the most common way that models are productionized. HTTP endpoints are flexible and can serve requests for model predictions.

For more information, see [Model Deployments](https://docs.oracle.com/en-us/iaas/data-science/using/model-dep-about.htm)

 * OpenAPI spec version: 20240424
 * 
 *
 * NOTE: This class is auto generated by OracleSDKGenerator.
 * Do not edit the class manually.
 *
 * Copyright (c) 2020, 2025, Oracle and/or its affiliates.  All rights reserved.
 * This software is dual-licensed to you under the Universal Permissive License (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl or Apache License 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose either license.
 */

import common = require("oci-common");
import * as requests from "./request";
import * as model from "./model";
import * as responses from "./response";
import {
  composeResponse,
  composeRequest,
  GenericRetrier,
  developerToolConfiguration
} from "oci-common";
const Breaker = require("opossum");

// ===============================================
// This file is autogenerated - Please do not edit
// ===============================================

export enum ModelDeploymentApiKeys {}
/**
 * This service client uses {@link common.CircuitBreaker.DefaultConfiguration} for all the operations by default if no circuit breaker configuration is defined by the user.
 */
export class ModelDeploymentClient {
  protected static serviceEndpointTemplate =
    "https://md.datascience.{region}.oci.{secondLevelDomain}";
  protected static endpointServiceName = "";
  protected static serviceEndpointTemplatePerRealm = {
    "oc1": "https://modeldeployment.{region}.oci.customer-oci.com"
  };
  protected "_realmSpecificEndpointTemplateEnabled": boolean | undefined = undefined;
  protected "_endpoint": string = "";
  protected "_defaultHeaders": any = {};
  protected "_clientConfiguration": common.ClientConfiguration;
  protected _circuitBreaker: typeof Breaker | null = null;
  protected _httpOptions: any = undefined;
  protected _bodyDuplexMode: any = undefined;
  public targetService = "ModelDeployment";
  protected _regionId: string = "";
  protected "_region": common.Region;
  protected _lastSetRegionOrRegionId: string = "";

  protected _httpClient: common.HttpClient;
  protected _authProvider: common.AuthenticationDetailsProvider | undefined;

  constructor(params: common.AuthParams, clientConfiguration?: common.ClientConfiguration) {
    const requestSigner = params.authenticationDetailsProvider
      ? new common.DefaultRequestSigner(params.authenticationDetailsProvider)
      : null;
    this._authProvider = params.authenticationDetailsProvider;
    if (clientConfiguration) {
      this._clientConfiguration = clientConfiguration;
      this._circuitBreaker = clientConfiguration.circuitBreaker
        ? clientConfiguration.circuitBreaker!.circuit
        : null;
      this._httpOptions = clientConfiguration.httpOptions
        ? clientConfiguration.httpOptions
        : undefined;
      this._bodyDuplexMode = clientConfiguration.bodyDuplexMode
        ? clientConfiguration.bodyDuplexMode
        : undefined;
    }

    if (!developerToolConfiguration.isServiceEnabled("modeldeployment")) {
      let errmsg =
        "The developerToolConfiguration configuration disabled this service, this behavior is controlled by developerToolConfiguration.ociEnabledServiceSet variable. Please check if your local developer_tool_configuration file has configured the service you're targeting or contact the cloud provider on the availability of this service : ";
      throw errmsg.concat("modeldeployment");
    }

    // if circuit breaker is not created, check if circuit breaker system is enabled to use default circuit breaker
    const specCircuitBreakerEnabled = true;
    if (
      !this._circuitBreaker &&
      common.utils.isCircuitBreakerSystemEnabled(clientConfiguration!) &&
      (specCircuitBreakerEnabled || common.CircuitBreaker.DefaultCircuitBreakerOverriden)
    ) {
      this._circuitBreaker = new common.CircuitBreaker().circuit;
    }
    this._httpClient =
      params.httpClient ||
      new common.FetchHttpClient(
        requestSigner,
        this._circuitBreaker,
        this._httpOptions,
        this._bodyDuplexMode
      );

    if (
      params.authenticationDetailsProvider &&
      common.isRegionProvider(params.authenticationDetailsProvider)
    ) {
      const provider: common.RegionProvider = params.authenticationDetailsProvider;
      if (provider.getRegion()) {
        this.region = provider.getRegion();
      }
    }
  }

  /**
   * Get the endpoint that is being used to call (ex, https://www.example.com).
   */
  public get endpoint() {
    return this._endpoint;
  }

  /**
   * Sets the endpoint to call (ex, https://www.example.com).
   * @param endpoint The endpoint of the service.
   */
  public set endpoint(endpoint: string) {
    this._endpoint = endpoint;
    if (this.logger) this.logger.info(`ModelDeploymentClient endpoint set to ${this._endpoint}`);
  }

  public get logger() {
    return common.LOG.logger;
  }

  /**
   * Determines whether realm specific endpoint should be used or not.
   * Set realmSpecificEndpointTemplateEnabled to "true" if the user wants to enable use of realm specific endpoint template, otherwise set it to "false"
   * @param realmSpecificEndpointTemplateEnabled flag to enable the use of realm specific endpoint template
   */
  public set useRealmSpecificEndpointTemplate(realmSpecificEndpointTemplateEnabled: boolean) {
    this._realmSpecificEndpointTemplateEnabled = realmSpecificEndpointTemplateEnabled;
    if (this.logger)
      this.logger.info(
        `realmSpecificEndpointTemplateEnabled set to ${this._realmSpecificEndpointTemplateEnabled}`
      );
    if (this._lastSetRegionOrRegionId === common.Region.REGION_STRING) {
      this.endpoint = common.EndpointBuilder.createEndpointFromRegion(
        ModelDeploymentClient.serviceEndpointTemplate,
        this._region,
        ModelDeploymentClient.endpointServiceName,
        ModelDeploymentClient.serviceEndpointTemplatePerRealm,
        this._realmSpecificEndpointTemplateEnabled
      );
    } else if (this._lastSetRegionOrRegionId === common.Region.REGION_ID_STRING) {
      this.endpoint = common.EndpointBuilder.createEndpointFromRegionId(
        ModelDeploymentClient.serviceEndpointTemplate,
        this._regionId,
        ModelDeploymentClient.endpointServiceName,
        ModelDeploymentClient.serviceEndpointTemplatePerRealm,
        this._realmSpecificEndpointTemplateEnabled
      );
    }
  }

  /**
   * Sets the region to call (ex, Region.US_PHOENIX_1).
   * Note, this will call {@link #endpoint(String) endpoint} after resolving the endpoint.
   * @param region The region of the service.
   */
  public set region(region: common.Region) {
    this._region = region;
    this.endpoint = common.EndpointBuilder.createEndpointFromRegion(
      ModelDeploymentClient.serviceEndpointTemplate,
      region,
      ModelDeploymentClient.endpointServiceName,
      ModelDeploymentClient.serviceEndpointTemplatePerRealm,
      this._realmSpecificEndpointTemplateEnabled
    );
    this._lastSetRegionOrRegionId = common.Region.REGION_STRING;
  }

  /**
   * Sets the regionId to call (ex, 'us-phoenix-1').
   *
   * Note, this will first try to map the region ID to a known Region and call {@link #region(Region) region}.
   * If no known Region could be determined, it will create an endpoint assuming its in default Realm OC1
   * and then call {@link #endpoint(String) endpoint}.
   * @param regionId The public region ID.
   */
  public set regionId(regionId: string) {
    this._regionId = regionId;
    this.endpoint = common.EndpointBuilder.createEndpointFromRegionId(
      ModelDeploymentClient.serviceEndpointTemplate,
      regionId,
      ModelDeploymentClient.endpointServiceName,
      ModelDeploymentClient.serviceEndpointTemplatePerRealm,
      this._realmSpecificEndpointTemplateEnabled
    );
    this._lastSetRegionOrRegionId = common.Region.REGION_ID_STRING;
  }

  /**
   * Shutdown the circuit breaker used by the client when it is no longer needed
   */
  public shutdownCircuitBreaker() {
    if (this._circuitBreaker) {
      this._circuitBreaker.shutdown();
    }
  }

  /**
   * Close the provider if possible which in turn shuts down any associated circuit breaker
   */
  public closeProvider() {
    if (this._authProvider) {
      if (this._authProvider instanceof common.AbstractRequestingAuthenticationDetailsProvider)
        (<common.AbstractRequestingAuthenticationDetailsProvider>(
          this._authProvider
        )).closeProvider();
    }
  }

  /**
   * Close the client once it is no longer needed
   */
  public close() {
    this.shutdownCircuitBreaker();
    this.closeProvider();
  }

  /**
   * Invoking a model deployment calls the predict endpoint of the model deployment URI.
   * This endpoint takes sample data as input and is processed using the predict() function in score.py model artifact file
   *
   * This operation uses {@link common.OciSdkDefaultRetryConfiguration} by default if no retry configuration is defined by the user.
   * @param PredictRequest
   * @return PredictResponse
   * @throws OciError when an error occurs
   * @example Click {@link https://docs.oracle.com/en-us/iaas/tools/typescript-sdk-examples/latest/modeldeployment/Predict.ts.html |here} to see how to use Predict API.
   */
  public async predict(
    predictRequest: requests.PredictRequest
  ): Promise<responses.PredictResponse> {
    if (this.logger) this.logger.debug("Calling operation ModelDeploymentClient#predict.");
    const operationName = "predict";
    const apiReferenceLink = "";
    const pathParams = {
      "{modelDeploymentId}": predictRequest.modelDeploymentId
    };

    const queryParams = {};

    let headerParams = {
      "Content-Type": common.Constants.APPLICATION_JSON,
      "opc-request-id": predictRequest.opcRequestId
    };

    const specRetryConfiguration = common.OciSdkDefaultRetryConfiguration;
    const retrier = GenericRetrier.createPreferredRetrier(
      this._clientConfiguration ? this._clientConfiguration.retryConfiguration : undefined,
      predictRequest.retryConfiguration,
      specRetryConfiguration
    );
    if (this.logger) retrier.logger = this.logger;
    const request = await composeRequest({
      baseEndpoint: this._endpoint,
      defaultHeaders: this._defaultHeaders,
      path: "/{modelDeploymentId}/predict",
      method: "POST",
      bodyContent: common.ObjectSerializer.serialize(predictRequest.requestBody, "string"),
      pathParams: pathParams,
      headerParams: headerParams,
      queryParams: queryParams
    });
    try {
      const response = await retrier.makeServiceCall(
        this._httpClient,
        request,
        this.targetService,
        operationName,
        apiReferenceLink
      );
      const sdkResponse = composeResponse({
        responseObject: <responses.PredictResponse>{},
        body: await response.json(),
        bodyKey: "value",
        bodyModel: "string",
        type: "string",
        responseHeaders: [
          {
            value: response.headers.get("opc-request-id"),
            key: "opcRequestId",
            dataType: "string"
          }
        ]
      });

      return sdkResponse;
    } catch (err) {
      throw err;
    }
  }

  /**
   * Invoking a model deployment calls the predictWithResponseStream endpoint of the model deployment URI to get the streaming result.
   * This endpoint takes sample data as input and is processed using the predict() function in score.py model artifact file
   *
   * This operation uses {@link common.OciSdkDefaultRetryConfiguration} by default if no retry configuration is defined by the user.
   * @param PredictWithResponseStreamRequest
   * @return PredictWithResponseStreamResponse
   * @throws OciError when an error occurs
   * @example Click {@link https://docs.oracle.com/en-us/iaas/tools/typescript-sdk-examples/latest/modeldeployment/PredictWithResponseStream.ts.html |here} to see how to use PredictWithResponseStream API.
   */
  public async predictWithResponseStream(
    predictWithResponseStreamRequest: requests.PredictWithResponseStreamRequest
  ): Promise<responses.PredictWithResponseStreamResponse | ReadableStream<Uint8Array> | null> {
    if (this.logger)
      this.logger.debug("Calling operation ModelDeploymentClient#predictWithResponseStream.");
    const operationName = "predictWithResponseStream";
    const apiReferenceLink = "";
    const pathParams = {
      "{modelDeploymentId}": predictWithResponseStreamRequest.modelDeploymentId
    };

    const queryParams = {};

    let headerParams = {
      "Content-Type": common.Constants.APPLICATION_JSON,
      "opc-request-id": predictWithResponseStreamRequest.opcRequestId
    };

    const specRetryConfiguration = common.OciSdkDefaultRetryConfiguration;
    const retrier = GenericRetrier.createPreferredRetrier(
      this._clientConfiguration ? this._clientConfiguration.retryConfiguration : undefined,
      predictWithResponseStreamRequest.retryConfiguration,
      specRetryConfiguration
    );
    if (this.logger) retrier.logger = this.logger;
    const request = await composeRequest({
      baseEndpoint: this._endpoint,
      defaultHeaders: this._defaultHeaders,
      path: "/{modelDeploymentId}/predictWithResponseStream",
      method: "POST",
      bodyContent: common.ObjectSerializer.serialize(
        predictWithResponseStreamRequest.requestBody,
        "string"
      ),
      pathParams: pathParams,
      headerParams: headerParams,
      queryParams: queryParams
    });
    try {
      const response = await retrier.makeServiceCall(
        this._httpClient,
        request,
        this.targetService,
        operationName,
        apiReferenceLink
      );
      if (
        response.headers &&
        response.headers.get(common.Constants.CONTENT_TYPE_HEADER) ===
          common.Constants.SERVER_SIDE_EVENT_TEXT_STREAM
      ) {
        return response.body;
      }
      const sdkResponse = composeResponse({
        responseObject: <responses.PredictWithResponseStreamResponse>{},

        body: response.body!,
        bodyKey: "value",
        bodyModel: "string",
        responseHeaders: [
          {
            value: response.headers.get("opc-request-id"),
            key: "opcRequestId",
            dataType: "string"
          }
        ]
      });

      return sdkResponse;
    } catch (err) {
      throw err;
    }
  }
}
