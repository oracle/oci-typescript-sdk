/**
 * Generative AI Service Inference API
 * OCI Generative AI is a fully managed service that provides a set of state-of-the-art, customizable large language models (LLMs) that cover a wide range of use cases for text generation, summarization, and text embeddings. 

Use the Generative AI service inference API to access your custom model endpoints, or to try the out-of-the-box models to {@link #eNGenerative-ai-inferenceLatestChatResultChat(ENGenerative-ai-inferenceLatestChatResultChatRequest) eNGenerative-ai-inferenceLatestChatResultChat}, {@link #eNGenerative-ai-inferenceLatestGenerateTextResultGenerateText(ENGenerative-ai-inferenceLatestGenerateTextResultGenerateTextRequest) eNGenerative-ai-inferenceLatestGenerateTextResultGenerateText}, {@link #eNGenerative-ai-inferenceLatestSummarizeTextResultSummarizeText(ENGenerative-ai-inferenceLatestSummarizeTextResultSummarizeTextRequest) eNGenerative-ai-inferenceLatestSummarizeTextResultSummarizeText}, and {@link #eNGenerative-ai-inferenceLatestEmbedTextResultEmbedText(ENGenerative-ai-inferenceLatestEmbedTextResultEmbedTextRequest) eNGenerative-ai-inferenceLatestEmbedTextResultEmbedText}.

To use a Generative AI custom model for inference, you must first create an endpoint for that model. Use the {@link #eNGenerative-aiLatest(ENGenerative-aiLatestRequest) eNGenerative-aiLatest} to {@link #eNGenerative-aiLatestModel(ENGenerative-aiLatestModelRequest) eNGenerative-aiLatestModel} by fine-tuning an out-of-the-box model, or a previous version of a custom model, using your own data. Fine-tune the custom model on a {@link #eNGenerative-aiLatestDedicatedAiCluster(ENGenerative-aiLatestDedicatedAiClusterRequest) eNGenerative-aiLatestDedicatedAiCluster}. Then, create a {@link #eNGenerative-aiLatestDedicatedAiCluster(ENGenerative-aiLatestDedicatedAiClusterRequest) eNGenerative-aiLatestDedicatedAiCluster} with an {@link Endpoint} to host your custom model. For resource management in the Generative AI service, use the {@link #eNGenerative-aiLatest(ENGenerative-aiLatestRequest) eNGenerative-aiLatest}.

To learn more about the service, see the [Generative AI documentation](https://docs.oracle.com/iaas/Content/generative-ai/home.htm).

 * OpenAPI spec version: 20231130
 * 
 *
 * NOTE: This class is auto generated by OracleSDKGenerator.
 * Do not edit the class manually.
 *
 * Copyright (c) 2020, 2025, Oracle and/or its affiliates.  All rights reserved.
 * This software is dual-licensed to you under the Universal Permissive License (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl or Apache License 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose either license.
 */

import * as ApplyGuardrailsDetails from "./apply-guardrails-details";
export import ApplyGuardrailsDetails = ApplyGuardrailsDetails.ApplyGuardrailsDetails;
import * as ApplyGuardrailsResult from "./apply-guardrails-result";
export import ApplyGuardrailsResult = ApplyGuardrailsResult.ApplyGuardrailsResult;
import * as BaseChatRequest from "./base-chat-request";
export import BaseChatRequest = BaseChatRequest.BaseChatRequest;
import * as BaseChatResponse from "./base-chat-response";
export import BaseChatResponse = BaseChatResponse.BaseChatResponse;
import * as CategoryScore from "./category-score";
export import CategoryScore = CategoryScore.CategoryScore;
import * as ChatChoice from "./chat-choice";
export import ChatChoice = ChatChoice.ChatChoice;
import * as ChatContent from "./chat-content";
export import ChatContent = ChatContent.ChatContent;
import * as ChatDetails from "./chat-details";
export import ChatDetails = ChatDetails.ChatDetails;
import * as ChatResult from "./chat-result";
export import ChatResult = ChatResult.ChatResult;
import * as Choice from "./choice";
export import Choice = Choice.Choice;
import * as Citation from "./citation";
export import Citation = Citation.Citation;
import * as CohereMessage from "./cohere-message";
export import CohereMessage = CohereMessage.CohereMessage;
import * as CohereParameterDefinition from "./cohere-parameter-definition";
export import CohereParameterDefinition = CohereParameterDefinition.CohereParameterDefinition;
import * as CohereResponseFormat from "./cohere-response-format";
export import CohereResponseFormat = CohereResponseFormat.CohereResponseFormat;
import * as CohereTool from "./cohere-tool";
export import CohereTool = CohereTool.CohereTool;
import * as CohereToolCall from "./cohere-tool-call";
export import CohereToolCall = CohereToolCall.CohereToolCall;
import * as CohereToolResult from "./cohere-tool-result";
export import CohereToolResult = CohereToolResult.CohereToolResult;
import * as CompletionTokensDetails from "./completion-tokens-details";
export import CompletionTokensDetails = CompletionTokensDetails.CompletionTokensDetails;
import * as ContentModerationConfiguration from "./content-moderation-configuration";
export import ContentModerationConfiguration = ContentModerationConfiguration.ContentModerationConfiguration;
import * as ContentModerationResult from "./content-moderation-result";
export import ContentModerationResult = ContentModerationResult.ContentModerationResult;
import * as Document from "./document";
export import Document = Document.Document;
import * as DocumentRank from "./document-rank";
export import DocumentRank = DocumentRank.DocumentRank;
import * as EmbedTextDetails from "./embed-text-details";
export import EmbedTextDetails = EmbedTextDetails.EmbedTextDetails;
import * as EmbedTextResult from "./embed-text-result";
export import EmbedTextResult = EmbedTextResult.EmbedTextResult;
import * as GenerateTextDetails from "./generate-text-details";
export import GenerateTextDetails = GenerateTextDetails.GenerateTextDetails;
import * as GenerateTextResult from "./generate-text-result";
export import GenerateTextResult = GenerateTextResult.GenerateTextResult;
import * as GeneratedText from "./generated-text";
export import GeneratedText = GeneratedText.GeneratedText;
import * as GuardrailConfigs from "./guardrail-configs";
export import GuardrailConfigs = GuardrailConfigs.GuardrailConfigs;
import * as GuardrailsInput from "./guardrails-input";
export import GuardrailsInput = GuardrailsInput.GuardrailsInput;
import * as GuardrailsResults from "./guardrails-results";
export import GuardrailsResults = GuardrailsResults.GuardrailsResults;
import * as ImageUrl from "./image-url";
export import ImageUrl = ImageUrl.ImageUrl;
import * as LlmInferenceRequest from "./llm-inference-request";
export import LlmInferenceRequest = LlmInferenceRequest.LlmInferenceRequest;
import * as LlmInferenceResponse from "./llm-inference-response";
export import LlmInferenceResponse = LlmInferenceResponse.LlmInferenceResponse;
import * as Logprobs from "./logprobs";
export import Logprobs = Logprobs.Logprobs;
import * as Message from "./message";
export import Message = Message.Message;
import * as PersonallyIdentifiableInformationConfiguration from "./personally-identifiable-information-configuration";
export import PersonallyIdentifiableInformationConfiguration = PersonallyIdentifiableInformationConfiguration.PersonallyIdentifiableInformationConfiguration;
import * as PersonallyIdentifiableInformationResult from "./personally-identifiable-information-result";
export import PersonallyIdentifiableInformationResult = PersonallyIdentifiableInformationResult.PersonallyIdentifiableInformationResult;
import * as Prediction from "./prediction";
export import Prediction = Prediction.Prediction;
import * as PromptInjectionConfiguration from "./prompt-injection-configuration";
export import PromptInjectionConfiguration = PromptInjectionConfiguration.PromptInjectionConfiguration;
import * as PromptInjectionProtectionResult from "./prompt-injection-protection-result";
export import PromptInjectionProtectionResult = PromptInjectionProtectionResult.PromptInjectionProtectionResult;
import * as PromptTokensDetails from "./prompt-tokens-details";
export import PromptTokensDetails = PromptTokensDetails.PromptTokensDetails;
import * as RerankTextDetails from "./rerank-text-details";
export import RerankTextDetails = RerankTextDetails.RerankTextDetails;
import * as RerankTextResult from "./rerank-text-result";
export import RerankTextResult = RerankTextResult.RerankTextResult;
import * as ResponseFormat from "./response-format";
export import ResponseFormat = ResponseFormat.ResponseFormat;
import * as ResponseJsonSchema from "./response-json-schema";
export import ResponseJsonSchema = ResponseJsonSchema.ResponseJsonSchema;
import * as SearchQuery from "./search-query";
export import SearchQuery = SearchQuery.SearchQuery;
import * as ServingMode from "./serving-mode";
export import ServingMode = ServingMode.ServingMode;
import * as StreamOptions from "./stream-options";
export import StreamOptions = StreamOptions.StreamOptions;
import * as SummarizeTextDetails from "./summarize-text-details";
export import SummarizeTextDetails = SummarizeTextDetails.SummarizeTextDetails;
import * as SummarizeTextResult from "./summarize-text-result";
export import SummarizeTextResult = SummarizeTextResult.SummarizeTextResult;
import * as TokenLikelihood from "./token-likelihood";
export import TokenLikelihood = TokenLikelihood.TokenLikelihood;
import * as ToolCall from "./tool-call";
export import ToolCall = ToolCall.ToolCall;
import * as ToolChoice from "./tool-choice";
export import ToolChoice = ToolChoice.ToolChoice;
import * as ToolDefinition from "./tool-definition";
export import ToolDefinition = ToolDefinition.ToolDefinition;
import * as Usage from "./usage";
export import Usage = Usage.Usage;

import * as AssistantMessage from "./assistant-message";
export import AssistantMessage = AssistantMessage.AssistantMessage;
import * as CohereChatBotMessage from "./cohere-chat-bot-message";
export import CohereChatBotMessage = CohereChatBotMessage.CohereChatBotMessage;
import * as CohereChatRequest from "./cohere-chat-request";
export import CohereChatRequest = CohereChatRequest.CohereChatRequest;
import * as CohereChatResponse from "./cohere-chat-response";
export import CohereChatResponse = CohereChatResponse.CohereChatResponse;
import * as CohereLlmInferenceRequest from "./cohere-llm-inference-request";
export import CohereLlmInferenceRequest = CohereLlmInferenceRequest.CohereLlmInferenceRequest;
import * as CohereLlmInferenceResponse from "./cohere-llm-inference-response";
export import CohereLlmInferenceResponse = CohereLlmInferenceResponse.CohereLlmInferenceResponse;
import * as CohereResponseJsonFormat from "./cohere-response-json-format";
export import CohereResponseJsonFormat = CohereResponseJsonFormat.CohereResponseJsonFormat;
import * as CohereResponseTextFormat from "./cohere-response-text-format";
export import CohereResponseTextFormat = CohereResponseTextFormat.CohereResponseTextFormat;
import * as CohereSystemMessage from "./cohere-system-message";
export import CohereSystemMessage = CohereSystemMessage.CohereSystemMessage;
import * as CohereToolMessage from "./cohere-tool-message";
export import CohereToolMessage = CohereToolMessage.CohereToolMessage;
import * as CohereUserMessage from "./cohere-user-message";
export import CohereUserMessage = CohereUserMessage.CohereUserMessage;
import * as DedicatedServingMode from "./dedicated-serving-mode";
export import DedicatedServingMode = DedicatedServingMode.DedicatedServingMode;
import * as DeveloperMessage from "./developer-message";
export import DeveloperMessage = DeveloperMessage.DeveloperMessage;
import * as FunctionCall from "./function-call";
export import FunctionCall = FunctionCall.FunctionCall;
import * as FunctionDefinition from "./function-definition";
export import FunctionDefinition = FunctionDefinition.FunctionDefinition;
import * as GenericChatRequest from "./generic-chat-request";
export import GenericChatRequest = GenericChatRequest.GenericChatRequest;
import * as GenericChatResponse from "./generic-chat-response";
export import GenericChatResponse = GenericChatResponse.GenericChatResponse;
import * as GuardrailsTextInput from "./guardrails-text-input";
export import GuardrailsTextInput = GuardrailsTextInput.GuardrailsTextInput;
import * as ImageContent from "./image-content";
export import ImageContent = ImageContent.ImageContent;
import * as JsonObjectResponseFormat from "./json-object-response-format";
export import JsonObjectResponseFormat = JsonObjectResponseFormat.JsonObjectResponseFormat;
import * as JsonSchemaResponseFormat from "./json-schema-response-format";
export import JsonSchemaResponseFormat = JsonSchemaResponseFormat.JsonSchemaResponseFormat;
import * as LlamaLlmInferenceRequest from "./llama-llm-inference-request";
export import LlamaLlmInferenceRequest = LlamaLlmInferenceRequest.LlamaLlmInferenceRequest;
import * as LlamaLlmInferenceResponse from "./llama-llm-inference-response";
export import LlamaLlmInferenceResponse = LlamaLlmInferenceResponse.LlamaLlmInferenceResponse;
import * as OnDemandServingMode from "./on-demand-serving-mode";
export import OnDemandServingMode = OnDemandServingMode.OnDemandServingMode;
import * as StaticContent from "./static-content";
export import StaticContent = StaticContent.StaticContent;
import * as SystemMessage from "./system-message";
export import SystemMessage = SystemMessage.SystemMessage;
import * as TextContent from "./text-content";
export import TextContent = TextContent.TextContent;
import * as TextResponseFormat from "./text-response-format";
export import TextResponseFormat = TextResponseFormat.TextResponseFormat;
import * as ToolChoiceAuto from "./tool-choice-auto";
export import ToolChoiceAuto = ToolChoiceAuto.ToolChoiceAuto;
import * as ToolChoiceFunction from "./tool-choice-function";
export import ToolChoiceFunction = ToolChoiceFunction.ToolChoiceFunction;
import * as ToolChoiceNone from "./tool-choice-none";
export import ToolChoiceNone = ToolChoiceNone.ToolChoiceNone;
import * as ToolChoiceRequired from "./tool-choice-required";
export import ToolChoiceRequired = ToolChoiceRequired.ToolChoiceRequired;
import * as ToolMessage from "./tool-message";
export import ToolMessage = ToolMessage.ToolMessage;
import * as UserMessage from "./user-message";
export import UserMessage = UserMessage.UserMessage;
